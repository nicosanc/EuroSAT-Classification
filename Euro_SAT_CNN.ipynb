{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Project Dependencies"
      ],
      "metadata": {
        "id": "5YVqafVGiwkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGzy_mli-qdt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "from torch.nn.functional import softmax\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading The Dataset\n",
        "The following block of code should be run once to download the datasets, create directories for them, and extract all the contents into the respective directories. The website *zenodo* has an API that allows us to receive information in response to an HTTP request. These TIFF files are held in zip files and must be extracted to work with them directly."
      ],
      "metadata": {
        "id": "wS42StbQnZJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# the dataset includes the images as standard 3-band RGB (red, green, blue) images\n",
        "rgb_data_url = \"https://zenodo.org/record/7711810/files/EuroSAT_RGB.zip\"\n",
        "\n",
        "response_rgb = requests.get(rgb_data_url)\n",
        "response_rbg.raise_for_status()\n",
        "os.makedirs('RGB', exist_ok=False)\n",
        "\n",
        "with ZipFile(BytesIO(response_rgb.content)) as zip_file:\n",
        "  zip_file.extractall(f\"RGB\")"
      ],
      "metadata": {
        "id": "u-h1w2-q92Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DatasetLoader class\n",
        "This class' objective is to provide a set of instructions for how a dataloader, like that of PyTorch, can interact and load the files from our datasets. We define an initializer (constructor) with image paths in our directory, labels, any transformations we decide for the images. We also define a get item function, which the dataloader can use to efficiently extract individual files from the directories. The len function simply gives us the size of our dataset and the load image function uses the python library *PIL* to load the images. PIL is used instead of *Rasterio* in this case since we know we are working with basic 3-band images.\n",
        "\n"
      ],
      "metadata": {
        "id": "derjDcU4qrwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EuroSATDataset(Dataset):\n",
        "  def __init__(self, image_paths, labels, transform=None):\n",
        "    self.image_paths = image_paths\n",
        "    self.label_dict = {\"AnnualCrop\": 0, \"Forest\":1, \"HerbaceousVegetation\": 2,\n",
        "               \"Highway\": 3, \"Industrial\": 4, \"Pasture\": 5, \"PermanentCrop\": 6,\n",
        "               \"Residential\": 7, \"River\": 8, \"SeaLake\": 9}\n",
        "    self.labels = [self.label_dict[label] for label in labels]\n",
        "    self.transform = transform\n",
        "\n",
        "  def _load_image(self, idx):\n",
        "    image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    return image\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      image = self._load_image(idx)\n",
        "      label = self.labels[idx]\n",
        "      return image, label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyMF3EBRBnFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(root_dir):\n",
        "  image_paths = []\n",
        "  labels = []\n",
        "  for _, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
        "      class_dir = os.path.join(root_dir, class_name)\n",
        "      for file_name in os.listdir(class_dir):\n",
        "        if file_name.endswith(\".jpg\") or file_name.endswith('.tif'):\n",
        "            image_paths.append(os.path.join(class_dir, file_name))\n",
        "            labels.append(class_name)\n",
        "  return image_paths, labels"
      ],
      "metadata": {
        "id": "8HmLLMXvOKjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the data: RBG\n",
        "Here we will explore the dataset. This block of code will be run in the main block below and will result in visuals of the original images alongside their normalized counterparts\n"
      ],
      "metadata": {
        "id": "6oeIS1wk6QvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_data(dataset):\n",
        "    num_samples = 5\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "\n",
        "    mean= [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "    grid = gridspec.GridSpec(num_samples,2)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "      plt.figure(figsize=(10, num_samples*4))\n",
        "      image, label = dataset[idx]\n",
        "      original_image = image\n",
        "      original_image = denormalize_img(original_image, mean, std)\n",
        "      image = image.permute(1, 2, 0)\n",
        "      original_image = original_image.permute(1,2,0)\n",
        "\n",
        "      axis_1 = plt.subplot(grid[i,0])\n",
        "      axis_1.imshow(original_image)\n",
        "      axis_1.set_title(label)\n",
        "      axis_1.axis('off')\n",
        "\n",
        "      axis_2 = plt.subplot(grid[i,1])\n",
        "      axis_2.imshow(image)\n",
        "      axis_2.set_title(label)\n",
        "      axis_2.axis('off')\n",
        "\n",
        "      plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SaR4SIxk6mqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for removing normalization of images\n"
      ],
      "metadata": {
        "id": "ubi-Gf1CgpQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize_img(image, mean, std):\n",
        "  image = image.clone()\n",
        "  for t, m, s in zip(image, mean, std):\n",
        "        t.mul_(s).add_(m).clamp_\n",
        "  return image"
      ],
      "metadata": {
        "id": "CAFmKgcpT_HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "Our model will take advantage of the CNN (Convolutional Neural Network) architecture to help analyze the images and classify them. We will define the layers of the model, initialize the weights, then define the forward pass."
      ],
      "metadata": {
        "id": "YnZsTHDe88WB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 2, stride = 2)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 64, kernel_size = 5, padding = 2, stride = 2)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 8, kernel_size = 5, padding = 2, stride = 2)\n",
        "    self.fc_1 = nn.Linear(32, 128)\n",
        "    self.fc_2 = nn.Linear(128, num_classes)\n",
        "    self.dropout_fc = nn.Dropout(p=0.5)\n",
        "    self.batch_norm_1 = nn.BatchNorm2d(16)\n",
        "    self.batch_norm_2 = nn.BatchNorm2d(64)\n",
        "    self.batch_norm_3 = nn.BatchNorm2d(8)\n",
        "\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    for conv in [self.conv1, self.conv2, self.conv3]:\n",
        "        C_in = conv.weight.size(1)\n",
        "        nn.init.normal_(conv.weight, 0.0, 1 / sqrt(5 * 5 * C_in))\n",
        "        nn.init.constant_(conv.bias, 0.0)\n",
        "\n",
        "    D_in = self.fc_1.weight.size(1)\n",
        "    nn.init.normal_(self.fc_1.weight, 0.0, 1 / sqrt(D_in))\n",
        "    nn.init.constant_(self.fc_1.bias, 0.0)\n",
        "\n",
        "    D_in = self.fc_2.weight.size(1)\n",
        "    nn.init.normal_(self.fc_2.weight, 0.0, 1 / sqrt(D_in))\n",
        "    nn.init.constant_(self.fc_2.bias, 0.0)\n",
        "\n",
        "  def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "\n",
        "        x = F.relu(self.batch_norm_1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.batch_norm_2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.batch_norm_3(self.conv3(x)))\n",
        "        x = x.view(N, -1)\n",
        "        x = self.dropout_fc(F.relu(self.fc_1(x)))\n",
        "        x = self.dropout_fc(self.fc_2(x))\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "UvR32y6r-V85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training And Evaluation Helper Functions\n",
        "We define a train epoch function, an evaluate epoch function, and a save model function.\n",
        "We then run a loop in main that, while the loss is still steadily decreasing within our patience level, we train and evaluate another epoch. Once we reach our patience level, we break and plot the train and val loss."
      ],
      "metadata": {
        "id": "mTl5wCjfFt0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, epoch, stats, file):\n",
        "    state = {\n",
        "      'epoch': epoch,\n",
        "      'state_dict': model.state_dict(),\n",
        "      'stats': stats\n",
        "    }\n",
        "\n",
        "    filename = pathlib.Path(file)\n",
        "    torch.save(state, filename)\n"
      ],
      "metadata": {
        "id": "9kGJICmiDXw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def early_stopping(stats, curr_patience, prev_valid_loss):\n",
        "    if stats[-1][1] > prev_valid_loss:\n",
        "        curr_patience += 1\n",
        "    else:\n",
        "        curr_patience = 0\n",
        "        prev_valid_loss = stats[-1][1]\n",
        "    return curr_patience, prev_valid_loss"
      ],
      "metadata": {
        "id": "G-RBMFc_Rahc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(data_loader, model, criterion, optimizer):\n",
        "    model.cuda()\n",
        "    model.train()\n",
        "    for i, (X, y) in enumerate(data_loader):\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Load up the model with the training data loader\n",
        "        output = model(X)\n",
        "        # Calculate the loss using cross entropy loss func\n",
        "        loss = criterion(output, y)\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"Training batch loss {loss}\")"
      ],
      "metadata": {
        "id": "v4IlBlmFRiQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictions(logits):\n",
        "    pred = torch.argmax(logits, dim = 1)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "j5EUt4PaRetr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation functions\n",
        "These nested functions help break down the entire validation and test evaluation. Get metrics will produce the necessary metrics to collect our statistics. Eval Epoch makes use of thi information to fill our stats list, and will produce confusion matrix and classification report if the test loader is passed in"
      ],
      "metadata": {
        "id": "5zxaBrRShi3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_epoch(\n",
        "    train_load,\n",
        "    valid_load,\n",
        "    model,\n",
        "    criterion,\n",
        "    epoch,\n",
        "    stats,\n",
        "    test_load = None,\n",
        "    update_plot=True):\n",
        "\n",
        "    def get_metrics(load):\n",
        "        model.eval()\n",
        "        y_true, y_pred, y_score = [], [], []\n",
        "        correct, total = 0, 0\n",
        "        running_loss = []\n",
        "        for i, (X, y) in enumerate(load):\n",
        "            with torch.no_grad():\n",
        "          # our project leverages the GPU offered by colab so we're going to\n",
        "          # set the data to work with cuda\n",
        "                X, y = X.cuda(), y.cuda()\n",
        "                output = model(X)\n",
        "                predicted = predictions(output.data)\n",
        "                y_true.append(y)\n",
        "                y_pred.append(predicted)\n",
        "                y_score.append(softmax(output.data, dim = 1))\n",
        "                total += len(y)\n",
        "                correct += (predicted == y).sum().item()\n",
        "                running_loss.append(criterion(output, y).item())\n",
        "        y_true = torch.cat(y_true)\n",
        "        y_pred = torch.cat(y_pred)\n",
        "        y_score = torch.cat(y_score)\n",
        "        loss = np.mean(running_loss)\n",
        "        accuracy = correct / total\n",
        "        return accuracy, loss, y_true, y_score\n",
        "\n",
        "    train_accuracy, train_loss, _, _ = get_metrics(train_load)\n",
        "    print(f\"epoch {epoch}, {train_accuracy}, {train_loss}\")\n",
        "    valid_accuracy, valid_loss,_, _ = get_metrics(valid_load)\n",
        "    print(f\"epoch {epoch}, {valid_accuracy}, {valid_loss}\")\n",
        "    epoch_stats = [\n",
        "        valid_accuracy,\n",
        "        valid_loss,\n",
        "        train_accuracy,\n",
        "        train_loss,\n",
        "    ]\n",
        "\n",
        "    if test_load:\n",
        "        epoch_stats += get_metrics(test_load)\n",
        "        y_true, y_score = epoch_stats[-2], epoch_stats[-1]\n",
        "        y_pred = torch.argmax(y_score, dim = 1)\n",
        "\n",
        "        conf_mat = metrics.confusion_matrix(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
        "        plt.figure(figsize=(10,8))\n",
        "        sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "        class_report = metrics.classification_report(y_true.cpu().numpy(), y_pred.cpu())\n",
        "        print(class_report)\n",
        "\n",
        "    stats.append(epoch_stats)"
      ],
      "metadata": {
        "id": "fXPOeqdXF4pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Driver: Initializes model, downloads and prepares data, then trains and evaluates the model.\n"
      ],
      "metadata": {
        "id": "ZtvVediihV-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# make an instance of the model, set the loss func and optimizer\n",
        "model = ConvNet()\n",
        "model.cuda()\n",
        "#model = model.cuda()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = .001, weight_decay = .01)\n",
        "\n",
        "# initialize some useful variables for evaluating our model\n",
        "stats = []\n",
        "start_epoch = 0\n",
        "patience = 5\n",
        "current_patience = 0\n",
        "\n",
        "# create a transformations object for our dataset to inherit\n",
        "transform = transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# load in the dataset\n",
        "image_paths, labels = prepare_data(root_dir=pathlib.Path(f\"/content/RGB/EuroSAT_RGB\"))\n",
        "\n",
        "class_count = Counter(labels)\n",
        "class_names = list(class_count.keys())\n",
        "counts = list(class_count.values())\n",
        "\n",
        "\n",
        "plt.pie(counts, labels=class_names, colors=sns.color_palette('pastel'),\n",
        "        autopct='%.0f%%')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# --- split the data between train, valid, and test ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_paths, labels,\n",
        "                                                    test_size=0.2, random_state=84, stratify = labels)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test,\n",
        "                                                    test_size=0.5, random_state=84, stratify = y_test)\n",
        "\n",
        "\n",
        "train_dataset = EuroSATDataset(image_paths=X_train, labels=y_train, transform=transform)\n",
        "valid_dataset = EuroSATDataset(image_paths=X_valid, labels=y_valid, transform=transform)\n",
        "test_dataset = EuroSATDataset(image_paths=X_test, labels=y_test, transform=transform)\n",
        "\n",
        "visualize_data(train_dataset)\n",
        "test_load = DataLoader(test_dataset, batch_size = 32, shuffle = False, num_workers=os.cpu_count())\n",
        "train_load = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers=os.cpu_count())\n",
        "valid_load = DataLoader(valid_dataset, batch_size = 32, shuffle = False, num_workers=os.cpu_count())\n",
        "\n",
        "# To have a baseline validation loss to compare, we evaluate an epoch\n",
        "# of the model with random initialization\n",
        "\n",
        "eval_epoch(train_load, valid_load, model, criterion, start_epoch, stats\n",
        ")\n",
        "\n",
        "prev_valid_loss = stats[-1][1]\n",
        "print(stats[-1])\n",
        "\n",
        "while current_patience < patience:\n",
        "  # train model for an epoch\n",
        "    train_epoch(train_load, model, criterion, optimizer)\n",
        "    eval_epoch(train_load, valid_load, model, criterion, start_epoch, stats)\n",
        "    if prev_valid_loss > stats[-1][1]:\n",
        "        save_checkpoint(model, start_epoch, stats, 'best_model.pt')\n",
        "    current_patience, prev_valid_loss = early_stopping(stats, current_patience, prev_valid_loss)\n",
        "    start_epoch +=1\n",
        "\n",
        "# test the model against the test set\n",
        "model.load_state_dict(torch.load('best_model.pt')[\"state_dict\"])\n",
        "eval_epoch(train_load, valid_load, model, criterion, start_epoch, stats, test_load)\n",
        "\n",
        "test_accuracy, test_loss = stats[-1][-4:-2]\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OisA_vCJ67td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of Validation and Trianing Performance\n",
        "Below is a section that can be run once the training and validation has been completed in the code block above. It will load the last saved model (the last epoch of validation with a loss less than the previous) and grab the necessary statistics. It then will produce loss and accuracy plots for both the validation and training sets."
      ],
      "metadata": {
        "id": "Zi8lxc4ffu90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.load('best_model.pt')\n",
        "epochs = list(range(best_model[\"epoch\"]))\n",
        "stats = best_model[\"stats\"]\n",
        "valid_accuracy = [epoch[0] for epoch in stats[:]]\n",
        "valid_loss = [epoch[1] for epoch in stats[:]]\n",
        "train_accuracy = [epoch[2] for epoch in stats[:]]\n",
        "train_loss = [epoch[3] for epoch in stats[:]]\n",
        "\n",
        "# auroc curve\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, valid_loss, 'r', label = \"Validation Loss\")\n",
        "plt.plot(epochs, train_loss, 'g', label = \"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Scores\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, valid_accuracy, 'r', label = \"Validation Accuracy\")\n",
        "plt.plot(epochs, train_accuracy, 'g', label = \"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Scores\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fSLPCmub7kBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}